{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Abnormal Heartbeat Classification  \n\nGiven *ECG data about patients' hearts*, let's try to detect **abnormal heartbeats** in the data.\n\nWe will use a TensorFlow RNN to make our predictions. ","metadata":{}},{"cell_type":"markdown","source":"# Getting Started","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-06-04T06:25:39.713636Z","iopub.execute_input":"2023-06-04T06:25:39.713999Z","iopub.status.idle":"2023-06-04T06:25:45.231468Z","shell.execute_reply.started":"2023-06-04T06:25:39.713964Z","shell.execute_reply":"2023-06-04T06:25:45.230511Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dfs = [pd.read_csv('../input/heartbeat/ptbdb_' + x + '.csv') for x in ['normal', 'abnormal']]","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:45.233346Z","iopub.execute_input":"2023-06-04T06:25:45.233720Z","iopub.status.idle":"2023-06-04T06:25:46.624975Z","shell.execute_reply.started":"2023-06-04T06:25:45.233689Z","shell.execute_reply":"2023-06-04T06:25:46.624065Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"for df in dfs:\n    df.columns = list(range(len(df.columns)))","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.627077Z","iopub.execute_input":"2023-06-04T06:25:46.627609Z","iopub.status.idle":"2023-06-04T06:25:46.633402Z","shell.execute_reply.started":"2023-06-04T06:25:46.627568Z","shell.execute_reply":"2023-06-04T06:25:46.632559Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.concat(dfs, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n\ndata = data.rename({187: 'Label'}, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.635063Z","iopub.execute_input":"2023-06-04T06:25:46.635515Z","iopub.status.idle":"2023-06-04T06:25:46.682798Z","shell.execute_reply.started":"2023-06-04T06:25:46.635477Z","shell.execute_reply":"2023-06-04T06:25:46.681848Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.685708Z","iopub.execute_input":"2023-06-04T06:25:46.686110Z","iopub.status.idle":"2023-06-04T06:25:46.730127Z","shell.execute_reply.started":"2023-06-04T06:25:46.686070Z","shell.execute_reply":"2023-06-04T06:25:46.729121Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6  \\\n0      1.000000  0.887073  0.774146  0.713224  0.682021  0.699851  0.595840   \n1      1.000000  0.684376  0.395907  0.288863  0.262102  0.231405  0.234160   \n2      1.000000  0.645543  0.270195  0.089833  0.038997  0.064067  0.045265   \n3      0.995881  0.993821  0.959835  0.872297  0.542739  0.054583  0.000000   \n4      0.996020  0.323383  0.109453  0.035821  0.264677  0.342289  0.367164   \n...         ...       ...       ...       ...       ...       ...       ...   \n14545  1.000000  0.979786  0.621879  0.146849  0.000000  0.266944  0.356718   \n14546  1.000000  0.648015  0.424677  0.315160  0.223816  0.156384  0.156863   \n14547  0.931217  1.000000  0.465201  0.150183  0.035409  0.033374  0.049247   \n14548  1.000000  0.588291  0.120570  0.056962  0.136076  0.181646  0.182595   \n14549  0.946429  0.315668  0.063940  0.011521  0.067972  0.151498  0.273618   \n\n              7         8         9  ...  178  179  180  181  182  183  184  \\\n0      0.552749  0.469539  0.481426  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1      0.218811  0.207399  0.212121  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2      0.062674  0.059192  0.057799  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3      0.098867  0.156540  0.302781  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4      0.402985  0.401990  0.420896  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n14545  0.421522  0.450059  0.457788  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14546  0.122908  0.093735  0.122908  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14547  0.070818  0.078958  0.087505  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14548  0.185759  0.178481  0.186076  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n14549  0.391705  0.397465  0.425115  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       185  186  Label  \n0      0.0  0.0    1.0  \n1      0.0  0.0    1.0  \n2      0.0  0.0    1.0  \n3      0.0  0.0    1.0  \n4      0.0  0.0    1.0  \n...    ...  ...    ...  \n14545  0.0  0.0    0.0  \n14546  0.0  0.0    1.0  \n14547  0.0  0.0    1.0  \n14548  0.0  0.0    0.0  \n14549  0.0  0.0    1.0  \n\n[14550 rows x 188 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.887073</td>\n      <td>0.774146</td>\n      <td>0.713224</td>\n      <td>0.682021</td>\n      <td>0.699851</td>\n      <td>0.595840</td>\n      <td>0.552749</td>\n      <td>0.469539</td>\n      <td>0.481426</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.684376</td>\n      <td>0.395907</td>\n      <td>0.288863</td>\n      <td>0.262102</td>\n      <td>0.231405</td>\n      <td>0.234160</td>\n      <td>0.218811</td>\n      <td>0.207399</td>\n      <td>0.212121</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.645543</td>\n      <td>0.270195</td>\n      <td>0.089833</td>\n      <td>0.038997</td>\n      <td>0.064067</td>\n      <td>0.045265</td>\n      <td>0.062674</td>\n      <td>0.059192</td>\n      <td>0.057799</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995881</td>\n      <td>0.993821</td>\n      <td>0.959835</td>\n      <td>0.872297</td>\n      <td>0.542739</td>\n      <td>0.054583</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.156540</td>\n      <td>0.302781</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.996020</td>\n      <td>0.323383</td>\n      <td>0.109453</td>\n      <td>0.035821</td>\n      <td>0.264677</td>\n      <td>0.342289</td>\n      <td>0.367164</td>\n      <td>0.402985</td>\n      <td>0.401990</td>\n      <td>0.420896</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14545</th>\n      <td>1.000000</td>\n      <td>0.979786</td>\n      <td>0.621879</td>\n      <td>0.146849</td>\n      <td>0.000000</td>\n      <td>0.266944</td>\n      <td>0.356718</td>\n      <td>0.421522</td>\n      <td>0.450059</td>\n      <td>0.457788</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14546</th>\n      <td>1.000000</td>\n      <td>0.648015</td>\n      <td>0.424677</td>\n      <td>0.315160</td>\n      <td>0.223816</td>\n      <td>0.156384</td>\n      <td>0.156863</td>\n      <td>0.122908</td>\n      <td>0.093735</td>\n      <td>0.122908</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14547</th>\n      <td>0.931217</td>\n      <td>1.000000</td>\n      <td>0.465201</td>\n      <td>0.150183</td>\n      <td>0.035409</td>\n      <td>0.033374</td>\n      <td>0.049247</td>\n      <td>0.070818</td>\n      <td>0.078958</td>\n      <td>0.087505</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14548</th>\n      <td>1.000000</td>\n      <td>0.588291</td>\n      <td>0.120570</td>\n      <td>0.056962</td>\n      <td>0.136076</td>\n      <td>0.181646</td>\n      <td>0.182595</td>\n      <td>0.185759</td>\n      <td>0.178481</td>\n      <td>0.186076</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14549</th>\n      <td>0.946429</td>\n      <td>0.315668</td>\n      <td>0.063940</td>\n      <td>0.011521</td>\n      <td>0.067972</td>\n      <td>0.151498</td>\n      <td>0.273618</td>\n      <td>0.391705</td>\n      <td>0.397465</td>\n      <td>0.425115</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14550 rows × 188 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"y = data['Label'].copy()\nX = data.drop('Label', axis=1).copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.731595Z","iopub.execute_input":"2023-06-04T06:25:46.731938Z","iopub.status.idle":"2023-06-04T06:25:46.761719Z","shell.execute_reply.started":"2023-06-04T06:25:46.731907Z","shell.execute_reply":"2023-06-04T06:25:46.760922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.763290Z","iopub.execute_input":"2023-06-04T06:25:46.763846Z","iopub.status.idle":"2023-06-04T06:25:46.797843Z","shell.execute_reply.started":"2023-06-04T06:25:46.763803Z","shell.execute_reply":"2023-06-04T06:25:46.796804Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            0         1         2         3         4         5         6    \\\n8540   1.000000  0.834705  0.358711  0.163923  0.096708  0.100137  0.137860   \n10734  1.000000  0.783220  0.479365  0.206803  0.010884  0.078912  0.107937   \n13652  1.000000  0.789198  0.247764  0.000000  0.039662  0.105148  0.115274   \n5014   1.000000  0.783092  0.592754  0.418357  0.347826  0.314976  0.289372   \n11630  0.990495  0.670835  0.302151  0.000000  0.068534  0.074537  0.141571   \n...         ...       ...       ...       ...       ...       ...       ...   \n905    1.000000  0.668866  0.334133  0.069586  0.106179  0.244151  0.262148   \n5192   0.970892  0.406573  0.051643  0.065728  0.184038  0.205634  0.238498   \n12172  1.000000  0.770696  0.600526  0.543364  0.500657  0.496058  0.500657   \n235    1.000000  0.814031  0.646993  0.079065  0.063474  0.122494  0.208241   \n13349  1.000000  0.595644  0.281250  0.000000  0.137311  0.279356  0.377841   \n\n            7         8         9    ...       177       178       179  \\\n8540   0.131001  0.131001  0.147462  ...  0.000000  0.000000  0.000000   \n10734  0.113832  0.116553  0.113832  ...  0.063492  0.070748  0.094785   \n13652  0.105654  0.109030  0.108017  ...  0.000000  0.000000  0.000000   \n5014   0.275362  0.267150  0.276812  ...  0.000000  0.000000  0.000000   \n11630  0.253127  0.309155  0.310155  ...  0.000000  0.000000  0.000000   \n...         ...       ...       ...  ...       ...       ...       ...   \n905    0.238152  0.240552  0.246551  ...  0.000000  0.000000  0.000000   \n5192   0.227230  0.234742  0.271362  ...  0.000000  0.000000  0.000000   \n12172  0.523653  0.519054  0.520368  ...  0.000000  0.000000  0.000000   \n235    0.231626  0.263920  0.279510  ...  0.000000  0.000000  0.000000   \n13349  0.403409  0.402462  0.414773  ...  0.000000  0.000000  0.000000   \n\n            180       181       182  183  184  185  186  \n8540   0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n10734  0.142404  0.149206  0.155102  0.0  0.0  0.0  0.0  \n13652  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n5014   0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n11630  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n...         ...       ...       ...  ...  ...  ...  ...  \n905    0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n5192   0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n12172  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n235    0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n13349  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n\n[10185 rows x 187 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>177</th>\n      <th>178</th>\n      <th>179</th>\n      <th>180</th>\n      <th>181</th>\n      <th>182</th>\n      <th>183</th>\n      <th>184</th>\n      <th>185</th>\n      <th>186</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8540</th>\n      <td>1.000000</td>\n      <td>0.834705</td>\n      <td>0.358711</td>\n      <td>0.163923</td>\n      <td>0.096708</td>\n      <td>0.100137</td>\n      <td>0.137860</td>\n      <td>0.131001</td>\n      <td>0.131001</td>\n      <td>0.147462</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10734</th>\n      <td>1.000000</td>\n      <td>0.783220</td>\n      <td>0.479365</td>\n      <td>0.206803</td>\n      <td>0.010884</td>\n      <td>0.078912</td>\n      <td>0.107937</td>\n      <td>0.113832</td>\n      <td>0.116553</td>\n      <td>0.113832</td>\n      <td>...</td>\n      <td>0.063492</td>\n      <td>0.070748</td>\n      <td>0.094785</td>\n      <td>0.142404</td>\n      <td>0.149206</td>\n      <td>0.155102</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13652</th>\n      <td>1.000000</td>\n      <td>0.789198</td>\n      <td>0.247764</td>\n      <td>0.000000</td>\n      <td>0.039662</td>\n      <td>0.105148</td>\n      <td>0.115274</td>\n      <td>0.105654</td>\n      <td>0.109030</td>\n      <td>0.108017</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5014</th>\n      <td>1.000000</td>\n      <td>0.783092</td>\n      <td>0.592754</td>\n      <td>0.418357</td>\n      <td>0.347826</td>\n      <td>0.314976</td>\n      <td>0.289372</td>\n      <td>0.275362</td>\n      <td>0.267150</td>\n      <td>0.276812</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11630</th>\n      <td>0.990495</td>\n      <td>0.670835</td>\n      <td>0.302151</td>\n      <td>0.000000</td>\n      <td>0.068534</td>\n      <td>0.074537</td>\n      <td>0.141571</td>\n      <td>0.253127</td>\n      <td>0.309155</td>\n      <td>0.310155</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>1.000000</td>\n      <td>0.668866</td>\n      <td>0.334133</td>\n      <td>0.069586</td>\n      <td>0.106179</td>\n      <td>0.244151</td>\n      <td>0.262148</td>\n      <td>0.238152</td>\n      <td>0.240552</td>\n      <td>0.246551</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>0.970892</td>\n      <td>0.406573</td>\n      <td>0.051643</td>\n      <td>0.065728</td>\n      <td>0.184038</td>\n      <td>0.205634</td>\n      <td>0.238498</td>\n      <td>0.227230</td>\n      <td>0.234742</td>\n      <td>0.271362</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12172</th>\n      <td>1.000000</td>\n      <td>0.770696</td>\n      <td>0.600526</td>\n      <td>0.543364</td>\n      <td>0.500657</td>\n      <td>0.496058</td>\n      <td>0.500657</td>\n      <td>0.523653</td>\n      <td>0.519054</td>\n      <td>0.520368</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>1.000000</td>\n      <td>0.814031</td>\n      <td>0.646993</td>\n      <td>0.079065</td>\n      <td>0.063474</td>\n      <td>0.122494</td>\n      <td>0.208241</td>\n      <td>0.231626</td>\n      <td>0.263920</td>\n      <td>0.279510</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13349</th>\n      <td>1.000000</td>\n      <td>0.595644</td>\n      <td>0.281250</td>\n      <td>0.000000</td>\n      <td>0.137311</td>\n      <td>0.279356</td>\n      <td>0.377841</td>\n      <td>0.403409</td>\n      <td>0.402462</td>\n      <td>0.414773</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10185 rows × 187 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.799227Z","iopub.execute_input":"2023-06-04T06:25:46.799763Z","iopub.status.idle":"2023-06-04T06:25:46.809632Z","shell.execute_reply.started":"2023-06-04T06:25:46.799721Z","shell.execute_reply":"2023-06-04T06:25:46.808932Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"8540     0.0\n10734    0.0\n13652    0.0\n5014     1.0\n11630    1.0\n        ... \n905      1.0\n5192     1.0\n12172    1.0\n235      1.0\n13349    1.0\nName: Label, Length: 10185, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.812260Z","iopub.execute_input":"2023-06-04T06:25:46.812946Z","iopub.status.idle":"2023-06-04T06:25:46.820104Z","shell.execute_reply.started":"2023-06-04T06:25:46.812905Z","shell.execute_reply":"2023-06-04T06:25:46.819336Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(10185, 187)"},"metadata":{}}]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(X_train.shape[1],))\n\nexpand = tf.expand_dims(inputs, axis=2)\ngru = tf.keras.layers.GRU(256, return_sequences=True)(expand)\nflatten = tf.keras.layers.Flatten()(gru)\n\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:46.821571Z","iopub.execute_input":"2023-06-04T06:25:46.822165Z","iopub.status.idle":"2023-06-04T06:25:49.345369Z","shell.execute_reply.started":"2023-06-04T06:25:46.822121Z","shell.execute_reply":"2023-06-04T06:25:49.343684Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 187)]             0         \n_________________________________________________________________\ntf_op_layer_ExpandDims (Tens [(None, 187, 1)]          0         \n_________________________________________________________________\ngru (GRU)                    (None, 187, 256)          198912    \n_________________________________________________________________\nflatten (Flatten)            (None, 47872)             0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 47873     \n=================================================================\nTotal params: 246,785\nTrainable params: 246,785\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T06:25:49.346813Z","iopub.execute_input":"2023-06-04T06:25:49.347161Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n255/255 [==============================] - 4s 17ms/step - loss: 0.4568 - accuracy: 0.7732 - auc: 0.8185 - val_loss: 0.4171 - val_accuracy: 0.8031 - val_auc: 0.8465\nEpoch 2/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.4092 - accuracy: 0.8096 - auc: 0.8629 - val_loss: 0.3668 - val_accuracy: 0.8341 - val_auc: 0.8904\nEpoch 3/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.3706 - accuracy: 0.8294 - auc: 0.8899 - val_loss: 0.3654 - val_accuracy: 0.8257 - val_auc: 0.8897\nEpoch 4/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.3348 - accuracy: 0.8501 - auc: 0.9116 - val_loss: 0.3369 - val_accuracy: 0.8434 - val_auc: 0.9071\nEpoch 5/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.3098 - accuracy: 0.8618 - auc: 0.9254 - val_loss: 0.3199 - val_accuracy: 0.8714 - val_auc: 0.9203\nEpoch 6/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.2773 - accuracy: 0.8844 - auc: 0.9404 - val_loss: 0.2908 - val_accuracy: 0.8694 - val_auc: 0.9306\nEpoch 7/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.2506 - accuracy: 0.8995 - auc: 0.9514 - val_loss: 0.2807 - val_accuracy: 0.8837 - val_auc: 0.9423\nEpoch 8/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.2366 - accuracy: 0.9035 - auc: 0.9570 - val_loss: 0.2641 - val_accuracy: 0.8910 - val_auc: 0.9529\nEpoch 9/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.2085 - accuracy: 0.9140 - auc: 0.9671 - val_loss: 0.2080 - val_accuracy: 0.9180 - val_auc: 0.9667\nEpoch 10/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.1834 - accuracy: 0.9257 - auc: 0.9745 - val_loss: 0.2020 - val_accuracy: 0.9161 - val_auc: 0.9678\nEpoch 11/100\n255/255 [==============================] - 4s 16ms/step - loss: 0.1669 - accuracy: 0.9324 - auc: 0.9790 - val_loss: 0.2069 - val_accuracy: 0.9141 - val_auc: 0.9697\nEpoch 12/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.1559 - accuracy: 0.9375 - auc: 0.9818 - val_loss: 0.1711 - val_accuracy: 0.9323 - val_auc: 0.9793\nEpoch 13/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.1412 - accuracy: 0.9443 - auc: 0.9845 - val_loss: 0.1462 - val_accuracy: 0.9445 - val_auc: 0.9842\nEpoch 14/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.1295 - accuracy: 0.9502 - auc: 0.9870 - val_loss: 0.1454 - val_accuracy: 0.9499 - val_auc: 0.9845\nEpoch 15/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.1077 - accuracy: 0.9563 - auc: 0.9910 - val_loss: 0.1387 - val_accuracy: 0.9465 - val_auc: 0.9855\nEpoch 16/100\n255/255 [==============================] - 4s 15ms/step - loss: 0.0930 - accuracy: 0.9642 - auc: 0.9931 - val_loss: 0.1671 - val_accuracy: 0.9396 - val_auc: 0.9803\nEpoch 17/100\n 42/255 [===>..........................] - ETA: 2s - loss: 0.0987 - accuracy: 0.9606 - auc: 0.9924","output_type":"stream"}]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(X_test, y_test, verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\nprint(\"     Test AUC: {:.4f}\".format(results[2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The final result with 97.66% accuracy\n","metadata":{}}]}